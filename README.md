# Abstract
This report critically evaluates FiveThirtyEight’s pollster grading methodology and polling adjustments during the 2016 U.S. presidential election. Using national and state-level polling data, the analysis examines whether higher pollster grades correlated with greater prediction accuracy, lower bias, and smaller adjustment magnitudes. Contrary to expectations, grades such as C and C+ demonstrated lower bias and variance than higher grades, while no consistent relationship was found between grade and prediction accuracy. Adjustments reduced overall polling error but failed to eliminate a systematic skew toward Hillary Clinton, and in key swing states such as Wisconsin, Michigan, and Pennsylvania, predictions were notably inaccurate. The report also assesses the reliability of voter classification methods, finding “likely voter” models susceptible to educational bias and potential social desirability effects among “shy” Trump voters. Additional analysis of sample size effects suggests that larger samples were more predictive of accuracy than grades themselves. Overall, the findings indicate that FiveThirtyEight’s grading system, while normally distributed, is not a reliable indicator of poll quality, and that alternative weighting strategies or supplemental behavioral data may improve election forecasting.
